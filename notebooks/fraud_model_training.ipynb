{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b38d1f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, auc, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bdfa909a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belet\\AppData\\Local\\Temp\\ipykernel_27908\\2797984255.py:2: DtypeWarning: Columns (1,2,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  fraud_data = pd.read_csv('../data/preprocessed/Fraud_Data_preprocessed.csv')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load preprocessed datasets\n",
    "fraud_data = pd.read_csv('../data/preprocessed/Fraud_Data_preprocessed.csv')\n",
    "creditcard_data = pd.read_csv('../data/preprocessed/creditcard_preprocessed.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81a237cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = pd.read_csv('../data/creditcard.csv')\n",
    "creditcard_data = pd.read_csv('../data/preprocessed/creditcard_preprocessed.csv')\n",
    "\n",
    "# Add the 'Class' column from the original to the preprocessed\n",
    "creditcard_data['Class'] = df_orig['Class']\n",
    "\n",
    "# Save the updated preprocessed file\n",
    "creditcard_data.to_csv('../data/preprocessed/creditcard_preprocessed.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4fdbf8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Time', 'Amount', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Class']\n"
     ]
    }
   ],
   "source": [
    "print(creditcard_data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1c6f09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where y_fraud is NaN\n",
    "fraud_data_clean = fraud_data.dropna(subset=['class'])\n",
    "fraud_features = [col for col in fraud_data_clean.columns if col not in ['class', 'user_id', 'device_id', 'signup_time', 'purchase_time', 'ip_address', 'ip_address_int']]\n",
    "X_fraud = fraud_data_clean[fraud_features]\n",
    "y_fraud = fraud_data_clean['class']\n",
    "\n",
    "X_train_fraud, X_test_fraud, y_train_fraud, y_test_fraud = train_test_split(X_fraud, y_fraud, test_size=0.2, stratify=y_fraud, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0ffcb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Creditcard_Data ---\n",
    "credit_features = [col for col in creditcard_data.columns if col != 'Class']\n",
    "X_credit = creditcard_data[credit_features]\n",
    "y_credit = creditcard_data['Class']\n",
    "\n",
    "X_train_credit, X_test_credit, y_train_credit, y_test_credit = train_test_split(X_credit, y_credit, test_size=0.2, stratify=y_credit, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ce42106",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(model, X_test, y_test, dataset_name):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "    auc_pr = auc(recall, precision)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"\\n--- {dataset_name} ---\")\n",
    "    print(f\"AUC-PR: {auc_pr:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "617518cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fraud = X_train_fraud.fillna(0)\n",
    "X_test_fraud = X_test_fraud.fillna(0)\n",
    "X_train_credit = X_train_credit.fillna(0)\n",
    "X_test_credit = X_test_credit.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d659b350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Random Forest...\n",
      "\n",
      "--- Fraud_Data (Random Forest) ---\n",
      "AUC-PR: 0.9270\n",
      "F1-score: 0.8714\n",
      "Confusion Matrix:\n",
      " [[26386  1006]\n",
      " [ 4348 18132]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.96      0.91     27392\n",
      "         1.0       0.95      0.81      0.87     22480\n",
      "\n",
      "    accuracy                           0.89     49872\n",
      "   macro avg       0.90      0.88      0.89     49872\n",
      "weighted avg       0.90      0.89      0.89     49872\n",
      "\n",
      "\n",
      "--- Creditcard_Data (Random Forest) ---\n",
      "AUC-PR: 0.0029\n",
      "F1-score: 0.0000\n",
      "Confusion Matrix:\n",
      " [[56644     4]\n",
      " [   98     0]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56648\n",
      "           1       0.00      0.00      0.00        98\n",
      "\n",
      "    accuracy                           1.00     56746\n",
      "   macro avg       0.50      0.50      0.50     56746\n",
      "weighted avg       1.00      1.00      1.00     56746\n",
      "\n",
      "\n",
      "Model comparison complete. Choose the model with the highest AUC-PR and F1-score for best performance on your task.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Random Forest ---\n",
    "print(\"\\nTraining Random Forest...\")\n",
    "rf_fraud = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
    "rf_fraud.fit(X_train_fraud, y_train_fraud)\n",
    "evaluate_model(rf_fraud, X_test_fraud, y_test_fraud, \"Fraud_Data (Random Forest)\")\n",
    "\n",
    "rf_credit = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
    "rf_credit.fit(X_train_credit, y_train_credit)\n",
    "evaluate_model(rf_credit, X_test_credit, y_test_credit, \"Creditcard_Data (Random Forest)\")\n",
    "print(\"\\nModel comparison complete. Choose the model with the highest AUC-PR and F1-score for best performance on your task.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961cb623",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
